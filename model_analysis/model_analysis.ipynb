{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('../data/rating.csv.zip')\n",
    "animes = pd.read_csv('../data/anime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cleaning ratings to only allow values greater than -1\n",
    "#Cleaning animes to only allow TV Shows\n",
    "ratings = ratings[ratings.rating > -1]\n",
    "animes = animes[animes.type == 'TV']\n",
    "ratings = ratings[ratings.anime_id.isin(animes.anime_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3787, 7)\n",
      "(4364294, 3)\n"
     ]
    }
   ],
   "source": [
    "print animes.shape\n",
    "print ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68929\n",
      "3787\n"
     ]
    }
   ],
   "source": [
    "#Getting the amount of differents users\n",
    "nb_users = ratings.groupby(\"user_id\").user_id.nunique().shape[0]\n",
    "#Getting the amount of anime shows\n",
    "nb_shows = animes.shape[0]\n",
    "print nb_users\n",
    "print nb_shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Rewritting ratings dataframe to ajust user_id in sequences\n",
    "#We have 69600 users in ratings but we have 73516 different users id's\n",
    "#We need to create a test set, but we'll have data loss if we don't have the user_id in sequences\n",
    "actual_index = ratings.iloc[0,].user_id\n",
    "new_index = 0\n",
    "new_list_user_id = []\n",
    "for i in range(ratings.shape[0]):\n",
    "    if i % 120000 == 0:\n",
    "        print\"{0} %\".format((i / float(ratings.shape[0])) * 100.)\n",
    "    if ratings.iloc[i,].user_id != actual_index:\n",
    "        new_index += 1\n",
    "        actual_index = ratings.iloc[i,].user_id    \n",
    "    new_list_user_id.append(new_index)\n",
    "print actual_index\n",
    "print new_index        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Doing the same structure for anime data\n",
    "mapped_anime_ids = {}\n",
    "for i in range(animes.shape[0]):\n",
    "    mapped_anime_ids[animes.iloc[i,].anime_id] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(ratings.shape[0]):\n",
    "    if i % 120000 == 0:\n",
    "        print\"{0} %\".format((i / float(ratings.shape[0])) * 100.)\n",
    "    ratings.iloc[i,].anime_id = mapped_anime_ids[ratings.iloc[i,].anime_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings['user_id'] = new_list_user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Exporting new data set.\n",
    "ratings.to_csv('ratings_corrected.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Working with corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_corrected = pd.read_csv('./ratings_corrected.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Training and Test Set with Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set, test_set = train_test_split(ratings_corrected, test_size=0.2, random_state=42)\n",
    "training_set = training_set.drop(training_set.columns[[0]], axis=1)\n",
    "test_set = test_set.drop(test_set.columns[[0]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3190395</th>\n",
       "      <td>50219</td>\n",
       "      <td>673</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013110</th>\n",
       "      <td>31228</td>\n",
       "      <td>432</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252341</th>\n",
       "      <td>4139</td>\n",
       "      <td>432</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172058</th>\n",
       "      <td>49945</td>\n",
       "      <td>364</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193400</th>\n",
       "      <td>66048</td>\n",
       "      <td>432</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  anime_id  rating\n",
       "3190395    50219       673       7\n",
       "2013110    31228       432       8\n",
       "252341      4139       432       6\n",
       "3172058    49945       364       8\n",
       "4193400    66048       432      10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_set(data, n_rows, n_cols):\n",
    "        process_set = []\n",
    "        for i  in range(n_rows):\n",
    "            rated = data[data[:, 0] == i]\n",
    "            animes_rated = rated[:, 1]\n",
    "            ratings_obtained = rated[:, 2]\n",
    "            ratings = np.zeros(n_cols)\n",
    "            ratings[animes_rated] = ratings_obtained\n",
    "            process_set.append(list(ratings))\n",
    "        return process_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = np.array(training_set, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 408,  10],\n",
       "       [  0, 568,  10],\n",
       "       [  0, 882,  10]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[training_set[:, 0] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "training_set = convert_set(training_set, nb_users, nb_shows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set = convert_set(test_set, nb_users, nb_shows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Stacker AutoEncoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating SAE class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from types import *\n",
    "import numpy as np\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self, input_output_size, encoder_input=20, decoder_input=20):\n",
    "        super(SAE, self).__init__()\n",
    "        self.encoder = nn.Linear(input_output_size, encoder_input)\n",
    "        self.hidden_layers = []\n",
    "        self.decoder = nn.Linear(decoder_input, input_output_size)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.last_out = encoder_input\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #First step\n",
    "        x = self.activation(self.encoder(x))\n",
    "        #We only handle Linear and Dropout layers\n",
    "        for layer in self.hidden_layers:\n",
    "            if \"Linear\" in str(type(layer)):\n",
    "                #It's a linear layer\n",
    "                x = self.activation(layer(x))\n",
    "            else:\n",
    "                #It's a dropout layer\n",
    "                x = layer(x)\n",
    "        #Final Step\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def add_hiden_layer(self, out_features):\n",
    "        new_layer = nn.Linear(self.last_out, out_features)\n",
    "        self.last_out = out_features\n",
    "        self.hidden_layers.append(new_layer)\n",
    "        \n",
    "    def add_dropout(self, p=0.5):\n",
    "        new_dropout = nn.Dropout(p)\n",
    "        self.hidden_layers.append(new_dropout)\n",
    "        \n",
    "    def print_progress(self, message):\n",
    "        sys.stdout.write(\"\\r\" + message)\n",
    "        sys.stdout.flush()\n",
    "    def compile(self, optimizer='rmsprop', criterion='mse', lr=0.01, weight_decay=0.5):\n",
    "        if type(criterion) is StringType:\n",
    "            if criterion == 'mse':\n",
    "                self.criterion = nn.MSELoss()\n",
    "            else:\n",
    "                self.criterion = nn.L1Loss()\n",
    "        else:\n",
    "            self.criterion = criterion\n",
    "        if optimizer == 'rmsprop':\n",
    "            self.optimizer = optim.RMSprop(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        elif optimizer == 'adadelta':\n",
    "            self.optimizer = optim.Adadelta(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        elif optimizer == 'adam':\n",
    "            self.optimizer = optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        elif optimizer == 'sgd':\n",
    "            self.optimizer = optim.SGD(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        elif optimizer == 'adagrad':\n",
    "            self.optimizer = optim.Adagrad(self.parameters(), lr=lr, weight_decay=weight_decay)           \n",
    "            \n",
    "            \n",
    "    def fit(self, X, nb_epoch):\n",
    "        init_time = time()\n",
    "        for epoch in range(nb_epoch):\n",
    "            train_loss = 0\n",
    "            s = 0.\n",
    "            rows, columns = X.size()\n",
    "            init_iteration_time = time()\n",
    "            init_training_time = time()\n",
    "            for index in range(int(rows)):\n",
    "                input = Variable(X[index]).unsqueeze(0)\n",
    "                target = input.clone()\n",
    "                if torch.sum(target.data > 0) > 0:\n",
    "                    output = self.forward(input)\n",
    "                    target.require_grad = False\n",
    "                    output[target == 0] = 0\n",
    "                    loss = self.criterion(output, target)\n",
    "                    mean_corrector = columns/float(torch.sum(target.data > 0) + 1e-10)\n",
    "                    loss.backward()\n",
    "                    train_loss += np.sqrt(loss.data[0] * mean_corrector)\n",
    "                    s += 1.\n",
    "                    self.optimizer.step()\n",
    "                end_training_time = time()\n",
    "                self.print_progress(\"epoch: {0}/{1}, training: {2}/{3} - {4:.2%}, time: {5:.2f}s\".format(epoch + 1, nb_epoch,index + 1, rows, (index + 1)/float(rows), end_training_time - init_training_time))\n",
    "            end_iteration_time = time()\n",
    "            self.print_progress('epoch: {0}/{1}, training loss: {2}, total epoch time: {3:.2f}s\\n'.format(epoch + 1, nb_epoch, train_loss / s, end_iteration_time - init_iteration_time))\n",
    "        end_time = time()\n",
    "        self.print_progress(\"Total Training Time: {0:.2f}m\".format((end_time - init_time) / float(60)))\n",
    "            \n",
    "    def perform(self, X, y):\n",
    "        test_loss = 0\n",
    "        s = 0.\n",
    "        rows, columns = X.size()\n",
    "        for index in range(int(rows)):\n",
    "            input = Variable(X[index]).unsqueeze(0)\n",
    "            target = Variable(y[index]).unsqueeze(0)\n",
    "            if torch.sum(target.data > 0) > 0:\n",
    "                output = self.forward(input)\n",
    "                target.required_grad = False\n",
    "                output[target == 0] = 0\n",
    "                loss = self.criterion(output, target)\n",
    "                mean_corrector = columns/float(torch.sum(target.data > 0) + 1e-10)\n",
    "                test_loss += np.sqrt(loss.data[0] * mean_corrector)\n",
    "                s += 1.\n",
    "        print \"prediction loss {0}\".format(test_loss/s) \n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = []\n",
    "        rows, _ = X.size()\n",
    "        for index in range(int(rows)):\n",
    "            input = Variable(X[index]).unsqueeze(0)\n",
    "            output = self.forward(input)\n",
    "            prediction.append(output)\n",
    "        return prediction\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_epoch = 200\n",
    "for epoch in range(nb_epoch):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(nb_users):\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_shows/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.data[0]*mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print \"Hello World\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(training_set, 'tensor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
